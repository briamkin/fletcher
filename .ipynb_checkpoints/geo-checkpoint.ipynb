{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from geo_boundaries import *\n",
    "from county_geo import *\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.neighbors import KDTree\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import cnfg\n",
    "import json\n",
    "from geo import *\n",
    "# from vaderSentiment.vaderSentiment import sentiment as vaderSentiment\n",
    "# from textblob import TextBlob\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "import logging\n",
    "import logging.handlers\n",
    "import datetime\n",
    "import os.path\n",
    "from bson.json_util import dumps\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "tweets = client.fletcher.tweets\n",
    "# backup = tweets.find({\"$text\":{\"$search\":\"\\\"hillary clinton\\\", hillary, clinton\"}})\n",
    "# hillary = tweets.aggregate([{\"$match\":{\"$text\":{\"$search\":\"hillary\"}}}])\n",
    "# ,\n",
    "#      {\"$match\":{\"timestamp_ms\":{\"$gte\":100000}}}])\n",
    "# all_tweets = tweets.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_tweets = tweets.find()\n",
    "# backup.count()\n",
    "# query = tweets.aggregate([\n",
    "#             {\"$match\":{\"$text\":{\"$search\":\"hillary\"}}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for tweet in query:\n",
    "#     count += 1\n",
    "\n",
    "# print count\n",
    "candidate_search = { \"Lincoln Chafee\" : \"lincolnchafee chafee teamchafee teamlincolnchafee chafee2016 lincolnchafee2016 chafeeforpresident chafee4president\",  \"Hillary Clinton\" : \"hillaryclinton hillary teamhillary teamclinton teamhillaryclinton hillary2016 clinton2016 hillaryclinton2016 hillaryforamerica hillary4america hillaryforpresident hillary4president\",  \"Martin O'Malley\" : \"governoromalley martinomalley teamomalley teammartinomalley omalley2016 martinomalley2016 omalley4president omalleyforpresident\",  \"Bernie Sanders\" : \"berniesanders sensanders teambernie teamberniesanders bernie2016 sanders2016 berniesanders2016 sanders4president sandersforpresident bernie4president bernieforpresident berniesanderse4president berniesanderseforpresident\",  \"Ben Carson\" : \"realbencarson bencarson drbencarson teamcarson teambencarson bencarson2016 carson2016 carson4president carsonforpresident bencarson4president bencarsonforpresident\",  \"Ted Cruz\" : \"tedcruz sentedcruz teamcruz teamtedcruz tedcruz2016 cruzcrew cruz4president cruzforpresident tedcruz4president tedcruzforpresident\",  \"Carly Fiorina\" : \"carlyfiorina fiorina teamcarly teamfiorina teamcarlyfiorina carly2016 carly4president carlyforpresident carlyfiorina4president carlyfiorinaforpresident fiorina4president fiorinaforpresident\",  \"Lindsey Graham\" : \"linseygrahamsc lindseygraham grahamblog senlindseygraham teamgraham teamlindseygraham graham2016 lindseygraham2016 graham4president grahamforpresident lindseygraham4president lindseygrahamforpresident\",  \"George Pataki\" : \"pataki4president patakiforpresident georgepataki4president georgepatakiforpresident\",  \"Rand Paul\" : \"randpaul drrandpaul senatorrandpaul teamrand teamrandpaul randpaul2016 rand2016 standwithrand rand4president randforpresident paul4president paulforpresident randpaul4president randpaulforpresident\",  \"Rick Perry\" : \"governorperry rickperry teamrickperry perry2016 rickperry2016 perry4president perryforpresident rickperry4president rickperryforpresident\",  \"Marco Rubio\" : \"marcorubio rubio2016 marcorubio2016 teammarco teammarcorubio marco4president marcoforpresident rubio4president rubioforpresident marcorubio4president marcorubioforpresident\",  \"Rick Santorum\" : \"ricksantorum santorum2016 teamsantorum teamricksantorum santorum4president santorumforpresident ricksantorum4president ricksantorumforpresident\",  \"Mike Huckabee\" : \"govmikehuckabee mikehuckabee teamhuckabee teammikehuckabee huckabee2016 mikehuckabee2016 huckaboom huckabee4president huckabeeforpresident mikehuckabee4president mikehuckabeeforpresident\",  \"Jeb Bush\" : \"jebbush  teamjeb teamjebbush jeb2016 bush2016 jebbush2016 jeb jeb4president jebforpresident jebbush4president jebbushforpresident\",  \"Scott Walker\" : \"scottwalker teamscottwalker scottwalker2016 walker4president walkerforpresident scottwalker4president scottwalkerforpresident\" }\n",
    "\n",
    "def get_all_candidates(time):\n",
    "    candidate_tweets = {}\n",
    "    for key in candidate_search:\n",
    "        search_terms = candidate_search[key]\n",
    "        tweets = return_tweets(time, search_terms)\n",
    "        boosted_tweets = tweet_booststrapper(tweets)\n",
    "        candidate_tweets[key] = boosted_tweets\n",
    "    return candidate_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fips = {}\n",
    "\n",
    "for num in all_fips:\n",
    "    fips[num] = [0,0]\n",
    "\n",
    "for doc in all_tweets:\n",
    "    fips_num = doc['fips']\n",
    "    try:\n",
    "        fips_sent = doc['sentiment']['compound']\n",
    "    except:\n",
    "        fips_sent = 0\n",
    "    if fips_num in fips:\n",
    "        fips[fips_num][0] += 1\n",
    "        fips[fips_num][1] += fips_sent\n",
    "        \n",
    "for key in fips:\n",
    "    if fips[key][0] != 0:\n",
    "        fips[key][1] = float(fips[key][1]/fips[key][0])\n",
    "\n",
    "sentiment = {}\n",
    "tweets_total = {}\n",
    "tweet_density = {}\n",
    "\n",
    "for key in fips:\n",
    "    sentiment[key] = fips[key][1]\n",
    "    tweets_total[key] = fips[key][0]\n",
    "    tweet_density[key] = (fips[key][0]/fips_pop[key])*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_tweets = []\n",
    "for k, v in tweets_total.iteritems():\n",
    "    if v == 0:\n",
    "        no_tweets.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tweets_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nearest_counties_dictionary = {}\n",
    "\n",
    "# for key in geo_county_dictionary:\n",
    "#     nearest_counties = find_county(geo_county_dictionary[key], neighbors=11, all=1)\n",
    "#     nearest_counties_dictionary[key] = nearest_counties[1:]\n",
    "    \n",
    "# json.dump(nearest_counties_dictionary, open(\"nearest_counties_dictionary.py\",'w'))\n",
    "\n",
    "def county_booster(fips_dict, other_dict):\n",
    "    boosted_dict = {}\n",
    "    for key in fips_dict:\n",
    "        total_vol = fips_dict[key]\n",
    "        new_score = total_vol*other_dict[key]*15\n",
    "        total = (15*total_vol)\n",
    "        if total_vol < 10:\n",
    "            index = 10\n",
    "            for county in nearest_counties[key]:\n",
    "                new_score += (other_dict[county]*index)\n",
    "                index -= 1\n",
    "        new_score = new_score / (total+55)\n",
    "        boosted_dict[key] = new_score\n",
    "    return boosted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.110476612392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{41045: 0.11047661239168362}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# county_booster(tweets_total, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boosted_sentiment = county_booster(tweets_total, sentiment)\n",
    "boosted_density = county_booster(tweets_total, tweet_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('boosted_sentiment.tsv', 'w') as f:\n",
    "    [f.write('{0}\\t{1}\\n'.format(key, value)) for key, value in boosted_sentiment.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('tweets.tsv', 'w') as f:\n",
    "    [f.write('{0}\\t{1}\\n'.format(key, value)) for key, value in tweets_total.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('boosted_tweet_density.tsv', 'w') as f:\n",
    "    [f.write('{0}\\t{1}\\n'.format(key, value)) for key, value in boosted_density.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_dict = {}\n",
    "# for key in all_county_boundaries:\n",
    "#     points = all_county_boundaries[key]\n",
    "#     nest_level = find_nested(points)\n",
    "#     if nest_level == 0:\n",
    "#         new_array = []\n",
    "#         for point in points:\n",
    "#             new_array.append([point[1],point[0]])\n",
    "#         new_dict[key] = new_array\n",
    "#     else:\n",
    "#         new_array = []\n",
    "#         for sub_points in points:\n",
    "#             sub_array = []\n",
    "#             for point in sub_points:\n",
    "#                 sub_array.append([point[1],point[0]])\n",
    "#             new_array.append(sub_array)\n",
    "#         new_dict[key] = new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f = open('new_file.py', 'w')\n",
    "# f.write(str(new_dict)) \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# county_geo_dictionary[40.776557, -73.970174]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def in_polygon(point, poly):\n",
    "  x = point[0]\n",
    "  y = point[1]\n",
    "  n = len(poly)\n",
    "  status = False\n",
    "  p1x,p1y = poly[0]\n",
    "  for i in range(n+1):\n",
    "    p2x,p2y = poly[i % n]\n",
    "    if min(p1y,p2y) < y <= max(p1y,p2y):\n",
    "      if x <= max(p1x,p2x):\n",
    "        if p1y != p2y:\n",
    "          xinters = (y-p1y)*(p2x-p1x)/(p2y-p1y)+p1x\n",
    "        if p1x == p2x or x <= xinters:\n",
    "          status = not status\n",
    "    p1x,p1y = p2x,p2y\n",
    "\n",
    "  return status\n",
    "\n",
    "def find_nested(nested_list):\n",
    "    try:\n",
    "        nested_list[0][0][0]\n",
    "        nest = 1\n",
    "    except:\n",
    "        nest = 0\n",
    "    return nest\n",
    "    \n",
    "def find_county(point):\n",
    "    county_tree = joblib.load('geo_tree/county_tree.pkl') \n",
    "    dist, indices = county_tree.query(point, k=5)\n",
    "    fips_list = []\n",
    "    for index in indices[0]:\n",
    "        try:\n",
    "            fips = county_geo_dictionary[(county_geo[index][0],county_geo[index][1])]\n",
    "            fips_list.append(fips)\n",
    "        except:\n",
    "            pass\n",
    "    if len(fips_list) > 0:\n",
    "        try:\n",
    "            for fips_num in fips_list:\n",
    "                try:\n",
    "                    county_paths = all_county_boundaries[str(fips_num)]\n",
    "                    if find_nested(county_paths) == 0:\n",
    "                        if in_polygon(point, county_paths):\n",
    "                            return fips_num\n",
    "                            break\n",
    "                    else:\n",
    "                        for path in county_paths:\n",
    "                            try:\n",
    "                                if in_polygon(point, path):\n",
    "                                    return fips_num\n",
    "                                    break\n",
    "                            except:\n",
    "                                pass\n",
    "                except:\n",
    "                    pass\n",
    "        except:\n",
    "            return fips_list[0]\n",
    "    else:\n",
    "        return None\n",
    "    if dist[0][0] > 6:\n",
    "        return None\n",
    "    return fips_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31151\n"
     ]
    }
   ],
   "source": [
    "print find_county([40.533548, -97.290977])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midtown\n"
     ]
    }
   ],
   "source": [
    "locations = [[\"bronx\", [[40.915132, -73.912168],[40.799059, -73.918005],[40.814391, -73.779302],[40.881655, -73.782735]]], [\"harlem\", [[40.834370, -73.950320],[40.818913, -73.961478],[40.801243, -73.959247],[40.797084, -73.949290],[40.817614, -73.934012],[40.828006, -73.934871]]], [\"upper_west\", [[40.818913, -73.961478],[40.801243, -73.959247],[40.768767, -73.982015],[40.773057, -73.993516]]], [\"upper_east\", [[40.797084, -73.949290],[40.817614, -73.934012],[40.764275, -73.972852],[40.758798, -73.958775],[40.776219, -73.941094],[40.799159, -73.928306],]], [\"midtown\", [[40.801243, -73.959247],[40.768767, -73.982015],[40.764275, -73.972852],[40.758798, -73.958775],[40.726881, -73.971736],[40.745416, -74.015509]]], [\"downtown\", [[40.726881, -73.971736],[40.745416, -74.015509],[40.697279, -74.021947],[40.711984, -73.971307]]], [\"brooklyn\", [[40.738697, -73.965254],[40.707995, -73.972120],[40.704351, -73.996839],[40.674674, -74.029112],[40.607982, -74.049024],[40.559485, -74.020185],[40.601727, -73.820371],[40.694981, -73.869810]]], [\"queens\", [[40.694981, -73.869810],[40.738697, -73.965254],[40.791007, -73.908958],[40.801923, -73.775748],[40.731196, -73.705710],[40.574394, -73.754462],[0.544137, -73.952216],[40.566049, -73.915824],[40.601727, -73.820371]]], [\"san_fran\", [[37.707196, -122.503175],[37.711270, -122.348679],[37.837188, -122.364366],[37.800303, -122.527787]]], [\"west_bay\", [[37.416526, -121.994411],[37.361970, -122.120067],[37.627261, -122.498996],[37.707196, -122.503175],[37.711270, -122.348679]]], [\"east_bay\", [[37.486844, -121.872875],[37.451966, -121.947033],[37.502835, -122.102708],[37.961171, -122.443285],[38.080176, -122.165880]]], [\"south_bay\", [[37.486844, -121.872875],[37.451966, -121.947033],[37.416526, -121.994411],[37.361970, -122.120067],[37.222672, -121.927807],[37.305189, -121.750652]]]]\n",
    "def find_location(point):\n",
    "  for area in locations:\n",
    "    if in_polygon(point,area[1]):\n",
    "      return area[0]\n",
    "      break\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "print find_location([40.749898, -73.985726])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
