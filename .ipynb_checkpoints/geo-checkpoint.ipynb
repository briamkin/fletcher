{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import flask\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "from county_geo import *\n",
    "from twitter_functions import *\n",
    "import math\n",
    "from datetime import date, timedelta, datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim import corpora, models, similarities\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidate_slugs = {  \"lincolnchafee\" : \"Lincoln Chafee\", \"hillaryclinton\" : \"Hillary Clinton\", \"martinomalley\" : \"Martin O'Malley\", \"berniesanders\" : \"Bernie Sanders\", \"bencarson\" : \"Ben Carson\", \"tedcruz\" : \"Ted Cruz\", \"carlyfiorina\" : \"Carly Fiorina\", \"lindseygraham\" : \"Lindsey Graham\", \"georgepataki\" : \"George Pataki\", \"randpaul\" : \"Rand Paul\", \"rickperry\" : \"Rick Perry\", \"marcorubio\" : \"Marco Rubio\", \"ricksantorum\" : \"Rick Santorum\", \"mikehucakbee\" : \"Mike Huckabee\", \"jebbush\" : \"Jeb Bush\", \"scottwalker\" : \"Scott Walker\", \"donaldtrump\" : \"Donald Trump\" }\n",
    "\n",
    "all_candidates = [\"Lincoln Chafee\", \"Hillary Clinton\", \"Martin O'Malley\", \"Bernie Sanders\", \"Ben Carson\", \"Ted Cruz\", \"Carly Fiorina\", \"Lindsey Graham\", \"George Pataki\", \"Rand Paul\", \"Rick Perry\", \"Marco Rubio\", \"Rick Santorum\", \"Mike Huckabee\", \"Jeb Bush\", \"Scott Walker\", \"Donald Trump\"]\n",
    "\n",
    "top_candidates = [\"Hillary Clinton\", \"Bernie Sanders\", \"Ben Carson\", \"Ted Cruz\", \"Carly Fiorina\", \"Rand Paul\", \"Jeb Bush\", \"Donald Trump\"]\n",
    "\n",
    "top_democrats = [\"Lincoln Chafee\", \"Hillary Clinton\", \"Martin O'Malley\", \"Bernie Sanders\"]\n",
    "\n",
    "top_republicans = [\"Donald Trump\", \"Jeb Bush\", \"Carly Fiorina\", \"Jeb Bush\", \"Rick Santorum\", \"Rand Paul\", \"Ted Cruz\"]\n",
    "\n",
    "candidate_lists = { \"top\" : top_candidates, \"rep\" : top_republicans, \"dem\" : top_democrats, \"all\" : all_candidates }\n",
    "\n",
    "candidate_search = { \"Lincoln Chafee\" : \"lincolnchafee chafee teamchafee teamlincolnchafee chafee2016 lincolnchafee2016 chafeeforpresident chafee4president\",  \"Hillary Clinton\" : \"hillaryclinton hillary teamhillary teamclinton teamhillaryclinton hillary2016 clinton2016 hillaryclinton2016 hillaryforamerica hillary4america hillaryforpresident hillary4president\",  \"Martin O'Malley\" : \"governoromalley martinomalley teamomalley teammartinomalley omalley2016 martinomalley2016 omalley4president omalleyforpresident\",  \"Bernie Sanders\" : \"berniesanders sensanders teambernie teamberniesanders bernie2016 sanders2016 berniesanders2016 sanders4president sandersforpresident bernie4president bernieforpresident berniesanderse4president berniesanderseforpresident\",  \"Ben Carson\" : \"realbencarson bencarson drbencarson teamcarson teambencarson bencarson2016 carson2016 carson4president carsonforpresident bencarson4president bencarsonforpresident\",  \"Ted Cruz\" : \"tedcruz sentedcruz teamcruz teamtedcruz tedcruz2016 cruzcrew cruz4president cruzforpresident tedcruz4president tedcruzforpresident\",  \"Carly Fiorina\" : \"carlyfiorina fiorina teamcarly teamfiorina teamcarlyfiorina carly2016 carly4president carlyforpresident carlyfiorina4president carlyfiorinaforpresident fiorina4president fiorinaforpresident\",  \"Lindsey Graham\" : \"linseygrahamsc lindseygraham grahamblog senlindseygraham teamgraham teamlindseygraham graham2016 lindseygraham2016 graham4president grahamforpresident lindseygraham4president lindseygrahamforpresident\",  \"George Pataki\" : \"governorpataki govpataki pataki georgepataki pataki4president patakiforpresident georgepataki4president georgepatakiforpresident teampataki\",  \"Rand Paul\" : \"randpaul drrandpaul senatorrandpaul teamrand teamrandpaul randpaul2016 rand2016 standwithrand rand4president randforpresident paul4president paulforpresident randpaul4president randpaulforpresident\",  \"Rick Perry\" : \"governorperry rickperry teamrickperry perry2016 rickperry2016 perry4president perryforpresident rickperry4president rickperryforpresident\",  \"Marco Rubio\" : \"marcorubio rubio2016 marcorubio2016 teammarco teammarcorubio marco4president marcoforpresident rubio4president rubioforpresident marcorubio4president marcorubioforpresident\",  \"Rick Santorum\" : \"ricksantorum santorum2016 teamsantorum teamricksantorum santorum4president santorumforpresident ricksantorum4president ricksantorumforpresident\",  \"Mike Huckabee\" : \"govmikehuckabee mikehuckabee teamhuckabee teammikehuckabee huckabee2016 mikehuckabee2016 huckaboom huckabee4president huckabeeforpresident mikehuckabee4president mikehuckabeeforpresident\",  \"Jeb Bush\" : \"jebbush  teamjeb teamjebbush jeb2016 bush2016 jebbush2016 jeb jeb4president jebforpresident jebbush4president jebbushforpresident\",  \"Scott Walker\" : \"scottwalker teamscottwalker scottwalker2016 walker4president walkerforpresident scottwalker4president scottwalkerforpresident\", \"Donald Trump\" : \"donaldtrump realdonaldtrump teamdonaldtrump teamtrump trump2016 donaldtrump2016 donaltrump4president donaldtrumpforpresident trump4president trumpforpresident\"}\n",
    "\n",
    "stopwords = [\"@\", \"a\", \"about\", \"above\", \"across\", \"after\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"among\", \"an\", \"and\", \"another\", \"any\", \"anybody\", \"anyone\", \"anything\", \"anywhere\", \"are\", \"area\", \"areas\", \"around\", \"as\", \"ask\", \"asked\", \"asking\", \"asks\", \"at\", \"away\", \"b\", \"back\", \"backed\", \"backing\", \"backs\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"been\", \"before\", \"began\", \"behind\", \"being\", \"beings\", \"best\", \"better\", \"between\", \"big\", \"both\", \"but\", \"by\", \"c\", \"came\", \"can\", \"cannot\", \"case\", \"cases\", \"certain\", \"certainly\", \"clear\", \"clearly\", \"come\", \"could\", \"d\", \"did\", \"differ\", \"different\", \"differently\", \"do\", \"does\", \"done\", \"down\", \"down\", \"downed\", \"downing\", \"downs\", \"during\", \"e\", \"each\", \"early\", \"either\", \"end\", \"ended\", \"ending\", \"ends\", \"enough\", \"even\", \"evenly\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"f\", \"face\", \"faces\", \"fact\", \"facts\", \"far\", \"felt\", \"few\", \"find\", \"finds\", \"first\", \"for\", \"four\", \"from\", \"full\", \"fully\", \"further\", \"furthered\", \"furthering\", \"furthers\", \"g\", \"gave\", \"general\", \"generally\", \"get\", \"gets\", \"give\", \"given\", \"gives\", \"go\", \"going\", \"good\", \"goods\", \"got\", \"great\", \"greater\", \"greatest\", \"group\", \"grouped\", \"grouping\", \"groups\", \"h\", \"had\", \"has\", \"have\", \"having\", \"he\", \"her\", \"here\", \"herself\", \"high\", \"high\", \"high\", \"higher\", \"highest\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"i\", \"if\", \"important\", \"in\", \"interest\", \"interested\", \"interesting\", \"interests\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"j\", \"just\", \"k\", \"keep\", \"keeps\", \"kind\", \"knew\", \"know\", \"known\", \"knows\", \"l\", \"large\", \"largely\", \"last\", \"later\", \"latest\", \"least\", \"less\", \"let\", \"lets\", \"like\", \"likely\", \"long\", \"longer\", \"longest\", \"m\", \"made\", \"make\", \"making\", \"man\", \"many\", \"may\", \"me\", \"member\", \"members\", \"men\", \"might\", \"more\", \"most\", \"mostly\", \"mr\", \"mrs\", \"much\", \"must\", \"my\", \"myself\", \"n\", \"necessary\", \"need\", \"needed\", \"needing\", \"needs\", \"never\", \"new\", \"new\", \"newer\", \"newest\", \"next\", \"no\", \"nobody\", \"non\", \"noone\", \"not\", \"nothing\", \"now\", \"nowhere\", \"number\", \"numbers\", \"o\", \"of\", \"off\", \"often\", \"old\", \"older\", \"oldest\", \"on\", \"once\", \"one\", \"only\", \"open\", \"opened\", \"opening\", \"opens\", \"or\", \"order\", \"ordered\", \"ordering\", \"orders\", \"other\", \"others\", \"our\", \"out\", \"over\", \"p\", \"part\", \"parted\", \"parting\", \"parts\", \"per\", \"perhaps\", \"place\", \"places\", \"point\", \"pointed\", \"pointing\", \"points\", \"possible\", \"present\", \"presented\", \"presenting\", \"presents\", \"problem\", \"problems\", \"put\", \"puts\", \"q\", \"quite\", \"r\", \"rather\", \"really\", \"right\", \"right\", \"room\", \"rooms\", \"s\", \"said\", \"same\", \"saw\", \"say\", \"says\", \"second\", \"seconds\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"sees\", \"several\", \"shall\", \"she\", \"should\", \"show\", \"showed\", \"showing\", \"shows\", \"side\", \"sides\", \"since\", \"small\", \"smaller\", \"smallest\", \"so\", \"some\", \"somebody\", \"someone\", \"something\", \"somewhere\", \"state\", \"states\", \"still\", \"still\", \"such\", \"sure\", \"t\", \"take\", \"taken\", \"than\", \"that\", \"the\", \"their\", \"them\", \"then\", \"there\", \"therefore\", \"these\", \"they\", \"thing\", \"things\", \"think\", \"thinks\", \"this\", \"those\", \"though\", \"thought\", \"thoughts\", \"three\", \"through\", \"thus\", \"to\", \"today\", \"together\", \"too\", \"took\", \"toward\", \"turn\", \"turned\", \"turning\", \"turns\", \"two\", \"u\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"use\", \"used\", \"uses\", \"v\", \"very\", \"w\", \"want\", \"wanted\", \"wanting\", \"wants\", \"was\", \"way\", \"ways\", \"we\", \"well\", \"wells\", \"went\", \"were\", \"what\", \"when\", \"where\", \"whether\", \"which\", \"while\", \"who\", \"whole\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"work\", \"worked\", \"working\", \"works\", \"would\", \"x\", \"y\", \"year\", \"years\", \"yet\", \"you\", \"young\", \"younger\", \"youngest\", \"your\", \"yours\", \"z\"]\n",
    "\n",
    "candidate_stop_words = {'Ben Carson': ['realbencarson','bencarson','drbencarson','teamcarson','teambencarson','bencarson2016','carson2016','carson4president','carsonforpresident','bencarson4president','bencarsonforpresident'],'Bernie Sanders': ['berniesanders','sensanders','teambernie','teamberniesanders','bernie2016','sanders2016','berniesanders2016','sanders4president','sandersforpresident','bernie4president','bernieforpresident','berniesanderse4president','berniesanderseforpresident'],'Carly Fiorina': ['carlyfiorina','fiorina','teamcarly','teamfiorina','teamcarlyfiorina','carly2016','carly4president','carlyforpresident','carlyfiorina4president','carlyfiorinaforpresident','fiorina4president','fiorinaforpresident'],'Donald Trump': ['donaldtrump','realdonaldtrump','teamdonaldtrump','teamtrump','trump2016','donaldtrump2016','donaltrump4president','donaldtrumpforpresident','trump4president','trumpforpresident'],'George Pataki': ['governorpataki','govpataki','pataki','georgepataki','pataki4president','patakiforpresident','georgepataki4president','georgepatakiforpresident','teampataki'],'Hillary Clinton': ['hillaryclinton','hillary','teamhillary','teamclinton','teamhillaryclinton','hillary2016','clinton2016','hillaryclinton2016','hillaryforamerica','hillary4america','hillaryforpresident','hillary4president'],'Jeb Bush': ['jebbush','teamjeb','teamjebbush','jeb2016','bush2016','jebbush2016','jeb','jeb4president','jebforpresident','jebbush4president','jebbushforpresident'],'Lincoln Chafee': ['lincolnchafee','chafee','teamchafee','teamlincolnchafee','chafee2016','lincolnchafee2016','chafeeforpresident','chafee4president'],'Lindsey Graham': ['linseygrahamsc','lindseygraham','grahamblog','senlindseygraham','teamgraham','teamlindseygraham','graham2016','lindseygraham2016','graham4president','grahamforpresident','lindseygraham4president','lindseygrahamforpresident'],'Marco Rubio': ['marcorubio','rubio2016','marcorubio2016','teammarco','teammarcorubio','marco4president','marcoforpresident','rubio4president','rubioforpresident','marcorubio4president','marcorubioforpresident'],\"Martin O'Malley\": ['governoromalley','martinomalley','teamomalley','teammartinomalley','omalley2016','martinomalley2016','omalley4president','omalleyforpresident'],'Mike Huckabee': ['govmikehuckabee','mikehuckabee','teamhuckabee','teammikehuckabee','huckabee2016','mikehuckabee2016','huckaboom','huckabee4president','huckabeeforpresident','mikehuckabee4president','mikehuckabeeforpresident'],'Rand Paul': ['randpaul','drrandpaul','senatorrandpaul','teamrand','teamrandpaul','randpaul2016','rand2016','standwithrand','rand4president','randforpresident','paul4president','paulforpresident','randpaul4president','randpaulforpresident'],'Rick Perry': ['governorperry','rickperry','teamrickperry','perry2016','rickperry2016','perry4president','perryforpresident','rickperry4president','rickperryforpresident'],'Rick Santorum': ['ricksantorum','santorum2016','teamsantorum','teamricksantorum','santorum4president','santorumforpresident','ricksantorum4president','ricksantorumforpresident'],'Scott Walker': ['scottwalker','teamscottwalker','scottwalker2016','walker4president','walkerforpresident','scottwalker4president','scottwalkerforpresident'],'Ted Cruz': ['tedcruz','sentedcruz','teamcruz','teamtedcruz','tedcruz2016','cruzcrew','cruz4president','cruzforpresident','tedcruz4president',\n",
    "  'tedcruzforpresident']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return Latest Tweets for Live Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_last_tweets():\n",
    "    current_epoch_time = int(time.time())\n",
    "    last_day = (current_epoch_time-86400)*1000\n",
    "    all_search = \"\"\n",
    "    for key in candidate_search:\n",
    "        all_search += (candidate_search[key] + \" \")\n",
    "    client = MongoClient()\n",
    "    db = client.fletcher.tweets\n",
    "    tweets = []\n",
    "    query = db.aggregate([\n",
    "            {\"$match\":{\"$text\":{\"$search\":all_search}}},\n",
    "            {\"$match\":{\"timestamp_ms\":{\"$gte\":last_day}}}])\n",
    "    for tweet in query:\n",
    "        try:\n",
    "            tweets.append({\n",
    "                            'text':tweet['text'],\n",
    "                            'screen_name':tweet['screen_name'],\n",
    "                            'timestamp':tweet['timestamp_ms'],\n",
    "                            'profile_img':tweet['profile_img']\n",
    "                        })\n",
    "        except:\n",
    "            pass\n",
    "    sorted_tweets = sorted(tweets, key=itemgetter('timestamp'))\n",
    "    return sorted_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return_last_tweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Get Tweets Based on Time and Search Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_tweets(day, search_terms=\"\", all_results=0):\n",
    "    today_epoch = int(date.today().strftime('%s'))\n",
    "    start_time = (today_epoch - (day*86400))*1000\n",
    "    end_time = start_time + 86399999\n",
    "    if all_results==1:\n",
    "        start_time = 0\n",
    "        end_time = (today_epoch+86400)*1000\n",
    "    client = MongoClient()\n",
    "    db = client.fletcher.tweets\n",
    "    tweets = {}\n",
    "    if search_terms != \"\":\n",
    "        query = db.aggregate([\n",
    "            {\"$match\":{\"$text\":{\"$search\":search_terms}}},\n",
    "            {\"$match\":{\"timestamp_ms\":{\"$gte\":start_time,\"$lt\":end_time}}}])\n",
    "    else:\n",
    "        query = db.aggregate([\n",
    "            {\"$match\":{\"timestamp_ms\":{\"$gte\":start_time,\"$lt\":end_time}}}])\n",
    "    for tweet in query:\n",
    "        fips = tweet['fips']\n",
    "        if fips in tweets:\n",
    "            tweets[fips]['volume'] += 1\n",
    "            try:\n",
    "                tweets[fips]['sentiment'] += tweet['sentiment']['compound']\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            tweets[fips] = {}\n",
    "            tweets[fips]['volume'] = 1\n",
    "            try:\n",
    "                tweets[fips]['sentiment'] = tweet['sentiment']['compound']\n",
    "            except:\n",
    "                tweets[fips]['sentiment'] = 0\n",
    "    for x in tweets:\n",
    "        tweets[x]['sentiment'] = tweets[x]['sentiment']/tweets[x]['volume']\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Tweet Boostrapping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tweet_booststrapper(dict, n=5):\n",
    "    bootstrap_dict = {}\n",
    "    for key in all_fips:\n",
    "        try:\n",
    "            volume = dict[key]['volume']\n",
    "            sentiment = dict[key]['sentiment']\n",
    "        except:\n",
    "            volume = 0\n",
    "            sentiment = 0\n",
    "        if volume < 100:\n",
    "            new_sent, new_vol, weight, new_mult = 0, 0, 10, 0\n",
    "            for county in nearest_counties[key]:\n",
    "                try:\n",
    "                    new_vol += dict[county]['volume']*weight\n",
    "                    new_sent += dict[county]['sentiment']*weight\n",
    "                    new_mult += weight\n",
    "                except:\n",
    "                    pass\n",
    "                weight -= 1\n",
    "            new_vol = (volume*(volume/100))+((new_vol/55)*((100-volume)/100))\n",
    "            if new_mult > 0:\n",
    "                new_sent = (volume*(volume/100))+((new_sent/new_mult)*((100-volume)/100))\n",
    "            else:\n",
    "                new_sent = sentiment\n",
    "        else:\n",
    "            new_vol = volume\n",
    "            new_sent = sentiment\n",
    "        bootstrap_dict[key] = {}\n",
    "        bootstrap_dict[key]['volume'] = new_vol\n",
    "        bootstrap_dict[key]['sentiment'] = new_sent\n",
    "    if n > 0:\n",
    "        n -= 1\n",
    "        return tweet_booststrapper(bootstrap_dict, n)\n",
    "    for key in bootstrap_dict:\n",
    "        bootstrap_sent = bootstrap_dict[key]['sentiment']\n",
    "        if bootstrap_sent < 0:\n",
    "            bootstrap_sent = -((-bootstrap_sent)**(0.3))\n",
    "        else:\n",
    "            bootstrap_sent **= (0.3)\n",
    "        bootstrap_dict[key]['sentiment'] = bootstrap_sent\n",
    "        bootstrap_dict[key]['volume'] *= 1500\n",
    "    return bootstrap_dict\n",
    "\n",
    "def convert_tweet_boostrapper_to_tsv(bootstrap_dict):\n",
    "    dicts = {}\n",
    "    sentiment_dict = [{'id' : 'id', 'rate' : 'rate'}]\n",
    "    volume_dict = [{'id' : 'id', 'rate' : 'rate'}]\n",
    "    for key in all_fips:\n",
    "        try:\n",
    "            sentiment_dict.append({\"id\":key,\"rate\":bootstrap_dict[key]['sentiment']})\n",
    "        except:\n",
    "            sentiment_dict.append({\"id\":key,\"rate\":0})\n",
    "        try:\n",
    "            volume_dict.append({\"id\":key,\"rate\":bootstrap_dict[key]['volume']})\n",
    "        except:\n",
    "            volume_dict.append({\"id\":key,\"rate\":0})\n",
    "    return {\"sentiment\": sentiment_dict, \"volume\": volume_dict}\n",
    "    with open('clinton_sentiment_tweets.tsv', 'w') as f:\n",
    "        [f.write('{0}\\t{1}\\n'.format(key['id'], key['rate'])) for key in bootstrapped_clinton_tweets['sentiment']]\n",
    "    with open('clinton_sentiment_tweets.tsv', 'w') as f:\n",
    "        [f.write('{0}\\t{1}\\n'.format(key['id'], key['rate'])) for key in bootstrapped_clinton_tweets['volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clinton_tweets = return_tweets(7, search_terms=\"clinton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bootstrapped_clinton_tweets = convert_tweet_boostrapper_to_json(tweet_booststrapper(clinton_tweets, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert_tweet_boostrapper_to_json(tweet_booststrapper(clinton_tweets, 5))\n",
    "# bootstrapped_clinton_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('clinton_sentiment_tweets.tsv', 'w') as f:\n",
    "    [f.write('{0}\\t{1}\\n'.format(key['id'], key['rate'])) for key in bootstrapped_clinton_tweets['sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Getting Values for Map based on Time and Candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_candidate_map(candidate, time=0):\n",
    "    all_tweets = []\n",
    "    tweet_volume = [{\"id\" : \"rate\"}]\n",
    "    tweet_sentiment = [{\"id\" : \"rate\"}]\n",
    "    total_volume = 0\n",
    "    total_sentiment = 0\n",
    "    total_sent_vol = 0\n",
    "    search_terms = candidate_search[candidate]\n",
    "    tweets = return_tweets(time, search_terms, all_results=all_results)\n",
    "    boosted_tweets = tweet_booststrapper(tweets,n)\n",
    "    for county in boosted_tweets:\n",
    "        county_volume = boosted_tweets[county]['volume']\n",
    "        county_sentiment = boosted_tweets[county]['sentiment']\n",
    "        total_volume += county_volume\n",
    "        if county_sentiment == None:\n",
    "            county_sentiment = 0;\n",
    "            # total_sentiment += (county_volume*county_sentiment)\n",
    "            # total_sent_vol += county_volume\n",
    "        try:\n",
    "            tweet_volume.append({\"id\" : county, \"rate\" : county_volume})\n",
    "            tweet_sentiment.append({\"id\" : county, \"rate\" : county_sentiment})\n",
    "        except:\n",
    "            tweet_volume.append({\"id\" : county, \"rate\" : 0})\n",
    "            tweet_sentiment.append({\"id\" : county, \"rate\" : 0})\n",
    "    all_data = {\"volume\" : tweet_volume, \"sentiment\" : tweet_sentiment}\n",
    "    # return all_data\n",
    "#     with open('boosted_sentiment.tsv', 'w') as f:\n",
    "#         [f.write('{0}\\t{1}\\n'.format(key, value)) for key, value in boosted_sentiment.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Candidates Based on Time as Python List to be transformed into JS Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_candidates_js_object(time=0, n=0, group_val=\"top\", individual=\"\"):\n",
    "    candidates_object = []\n",
    "    js_date = date.today() - timedelta(time)\n",
    "    js_date = js_date.strftime('%Y-%m-%d')\n",
    "    if individual != \"\":\n",
    "        iterator = [individual]\n",
    "    else:\n",
    "        iterator = candidate_lists[group_val]\n",
    "    for key in iterator:\n",
    "        total_volume = 0\n",
    "        total_sent_vol = 0\n",
    "        search_terms = candidate_search[key]\n",
    "        tweets = return_tweets(time, search_terms)\n",
    "        boosted_tweets = tweet_booststrapper(tweets,n)\n",
    "        candidate_dict = { \"group\" : key, \"date\" : js_date }\n",
    "        for county in boosted_tweets:\n",
    "            county_volume = boosted_tweets[county]['volume']\n",
    "            total_volume += county_volume\n",
    "        try:\n",
    "            candidate_dict['value'] = total_volume\n",
    "        except:\n",
    "            candidate_dict['value'] = 0\n",
    "        candidates_object.append(candidate_dict)\n",
    "    return candidates_object\n",
    "\n",
    "def get_all_candidates_js_objects(time=1, group_val=\"top\", individual=\"\"):\n",
    "    all_candidates_object = []\n",
    "    for x in reversed(range(time)):\n",
    "        all_candidates_object += get_candidates_js_object(x, 0, group_val, individual)\n",
    "    return all_candidates_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return LDA Gensim Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topics(candidate, day):\n",
    "    start_time = datetime.strptime(day, \"%Y-%m-%d\").date()\n",
    "    start_time = int(start_time.strftime('%s'))*1000\n",
    "    end_time = start_time + 86399999\n",
    "    try:\n",
    "        client = MongoClient()\n",
    "        tweets = client.fletcher.tweets\n",
    "        # tweets = tweets.aggregate([{\"$match\":{\"$text\":{\"$search\":candidate_search[candidate]}}}])\n",
    "        tweets = tweets.aggregate([{\"$match\":{\"$text\":{\"$search\":candidate_search[candidate]}}},\n",
    "                                   {\"$match\":{\"timestamp_ms\":{\"$gte\":start_time,\"$lt\":end_time}}}])\n",
    "        documents = []\n",
    "        pattern = re.compile(\"[^a-zA-Z ]\")\n",
    "        for tweet in tweets:\n",
    "            documents.append(pattern.sub('', tweet['text']))\n",
    "        stoplist = set(candidate_stop_words[candidate] + stopwords)\n",
    "        texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "                for document in documents]\n",
    "        frequency = defaultdict(int)\n",
    "        for text in texts:\n",
    "            for token in text:\n",
    "                frequency[token] += 1\n",
    "        texts = [[token for token in text if frequency[token] > 1]\n",
    "                for text in texts]\n",
    "        dictionary = corpora.Dictionary(texts)\n",
    "        lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=3, update_every=1, chunksize=10000, passes=10)\n",
    "        return lda.print_topics(3)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return Gensim Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topic_dictionary(candidate, day):\n",
    "    start_time = datetime.strptime(day, \"%Y-%m-%d\").date()\n",
    "    start_time = int(start_time.strftime('%s'))*1000\n",
    "    end_time = start_time + 86399999\n",
    "    client = MongoClient()\n",
    "    tweets = client.fletcher.tweets\n",
    "    tweets = tweets.aggregate([{\"$match\":{\"$text\":{\"$search\":candidate_search[candidate]}}},\n",
    "                               {\"$match\":{\"timestamp_ms\":{\"$gte\":start_time,\"$lt\":end_time}}}])\n",
    "    documents = []\n",
    "    pattern = re.compile(\"[^a-zA-Z ]\")\n",
    "    for tweet in tweets:\n",
    "        try:\n",
    "            documents.append(pattern.sub('', tweet['text']))\n",
    "        except:\n",
    "            continue\n",
    "    stoplist = set(candidate_stop_words[candidate] + stopwords)\n",
    "    texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "            for document in documents]\n",
    "    frequency = defaultdict(int)\n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "    texts = [[token for token in text if frequency[token] > 1]\n",
    "            for text in texts]\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    topics = []\n",
    "    for item in dictionary.items():\n",
    "        topics.append({\"text\" : item[1], \"size\" : item[0]})\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
